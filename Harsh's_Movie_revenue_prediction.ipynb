{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlX_2nVGzK1t",
        "outputId": "a54b583b-e175-47fd-84ae-298f2bf48991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-abf5c7176aba>:13: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  dataframe['release_year'] = pd.to_datetime(dataframe['release_date'], errors='coerce').dt.year\n",
            "<ipython-input-5-abf5c7176aba>:14: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  dataframe['release_month'] = pd.to_datetime(dataframe['release_date'], errors='coerce').dt.month\n",
            "<ipython-input-5-abf5c7176aba>:15: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  dataframe['release_weekday'] = pd.to_datetime(dataframe['release_date'], errors='coerce').dt.weekday\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline RMSE (Mean Prediction): 3.120879515582972\n",
            "Root Mean Squared Error (RMSE) on Training Data: 0.8746765521215467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-abf5c7176aba>:13: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  dataframe['release_year'] = pd.to_datetime(dataframe['release_date'], errors='coerce').dt.year\n",
            "<ipython-input-5-abf5c7176aba>:14: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  dataframe['release_month'] = pd.to_datetime(dataframe['release_date'], errors='coerce').dt.month\n",
            "<ipython-input-5-abf5c7176aba>:15: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  dataframe['release_weekday'] = pd.to_datetime(dataframe['release_date'], errors='coerce').dt.weekday\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       id  predicted_revenue\n",
            "0    2175       1.347346e+04\n",
            "1    2564       9.773048e+06\n",
            "2    1493       1.719902e+07\n",
            "3     585       8.367687e+05\n",
            "4    2038       1.343614e+04\n",
            "..    ...                ...\n",
            "595  1588       6.026098e+07\n",
            "596   439       1.887605e+07\n",
            "597  2908       1.063776e+07\n",
            "598  1179       8.921070e+04\n",
            "599  1443       1.121211e+07\n",
            "\n",
            "[600 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load training and test datasets\n",
        "train_data = pd.read_csv(\"./train.csv\")\n",
        "test_data = pd.read_csv(\"./test.csv\")\n",
        "\n",
        "# Define helper function to extract date features\n",
        "def extract_date_features(dataframe):\n",
        "    dataframe['release_year'] = pd.to_datetime(dataframe['release_date'], errors='coerce').dt.year\n",
        "    dataframe['release_month'] = pd.to_datetime(dataframe['release_date'], errors='coerce').dt.month\n",
        "    dataframe['release_weekday'] = pd.to_datetime(dataframe['release_date'], errors='coerce').dt.weekday\n",
        "\n",
        "# Step 1: Create 'log_revenue' in training data\n",
        "train_data['log_revenue'] = np.log(train_data['revenue'].replace(0, np.nan))\n",
        "\n",
        "# Handle missing values in training data\n",
        "numeric_columns = train_data.select_dtypes(include=['float64', 'int64']).columns\n",
        "categorical_columns = train_data.select_dtypes(include=['object']).columns\n",
        "\n",
        "train_data[numeric_columns] = train_data[numeric_columns].fillna(train_data[numeric_columns].median())\n",
        "train_data[categorical_columns] = train_data[categorical_columns].fillna(\"Unknown\")\n",
        "\n",
        "# Step 2: Feature engineering for dates in training data\n",
        "extract_date_features(train_data)\n",
        "\n",
        "# Step 3: One-hot encode categorical features in training data\n",
        "categorical_to_encode = ['main_genre', 'language']\n",
        "existing_categoricals = [col for col in categorical_to_encode if col in train_data.columns]\n",
        "train_data = pd.get_dummies(train_data, columns=existing_categoricals, drop_first=True)\n",
        "\n",
        "# Step 4: Scale numeric features in training data\n",
        "scaler = StandardScaler()\n",
        "numeric_features = ['budget', 'popularity', 'runtime', 'release_year', 'release_month', 'release_weekday']\n",
        "numeric_features = [col for col in numeric_features if col in train_data.columns]\n",
        "train_data[numeric_features] = scaler.fit_transform(train_data[numeric_features])\n",
        "\n",
        "# Step 5: Define features and target for training\n",
        "target = \"log_revenue\"\n",
        "features = train_data.columns.difference([target, 'revenue', 'belongs_to_collection', 'genres', 'homepage',\n",
        "                                          'imdb_id', 'original_language', 'original_title', 'overview',\n",
        "                                          'poster_path', 'production_companies', 'production_countries',\n",
        "                                          'release_date', 'spoken_languages', 'status', 'tagline', 'title',\n",
        "                                          'Keywords', 'cast', 'crew'])\n",
        "\n",
        "X_train = train_data[features]\n",
        "y_train = train_data[target]\n",
        "\n",
        "# Step 6: Calculate Baseline RMSE\n",
        "baseline_prediction = np.mean(y_train)  # Baseline prediction is the mean of log_revenue\n",
        "baseline_rmse = np.sqrt(mean_squared_error(y_train, [baseline_prediction] * len(y_train)))\n",
        "print(f\"Baseline RMSE (Mean Prediction): {baseline_rmse}\")\n",
        "\n",
        "\n",
        "# Step 6: Train the Random Forest model\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 7: Evaluate the model on training data\n",
        "y_train_pred = rf_model.predict(X_train)\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "print(f\"Root Mean Squared Error (RMSE) on Training Data: {train_rmse}\")\n",
        "\n",
        "# Step 8: Use test data to make predictions\n",
        "# Apply the same feature engineering steps to the test data\n",
        "extract_date_features(test_data)\n",
        "\n",
        "# Handle missing values in the test dataset\n",
        "test_numeric_columns = [col for col in numeric_features if col in test_data.columns]\n",
        "test_data[test_numeric_columns] = test_data[test_numeric_columns].fillna(0)\n",
        "\n",
        "# Check for existence of categorical columns before handling them\n",
        "existing_categoricals = [col for col in categorical_to_encode if col in test_data.columns]\n",
        "if existing_categoricals:\n",
        "    test_data[existing_categoricals] = test_data[existing_categoricals].fillna(\"Unknown\")\n",
        "    test_data = pd.get_dummies(test_data, columns=existing_categoricals, drop_first=True)\n",
        "\n",
        "# Align test data columns to match training data's features\n",
        "X_test = test_data.reindex(columns=features, fill_value=0)\n",
        "\n",
        "# Scale numeric features in test data\n",
        "if test_numeric_columns:\n",
        "    X_test[test_numeric_columns] = scaler.transform(X_test[test_numeric_columns])\n",
        "\n",
        "# Predict on the test dataset\n",
        "test_data['predicted_log_revenue'] = rf_model.predict(X_test)\n",
        "\n",
        "# Convert predicted log revenue to revenue\n",
        "test_data['predicted_revenue'] = np.exp(test_data['predicted_log_revenue'])\n",
        "\n",
        "# Display results\n",
        "print(test_data[['id', 'predicted_revenue']])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "\n",
        "xgb_model = XGBRegressor(\n",
        "    n_estimators=200,       # More trees for better learning\n",
        "    learning_rate=0.05,     # Smaller step size for better accuracy\n",
        "    max_depth=8,            # Allow deeper trees if data is complex\n",
        "    subsample=0.8,          # Use a portion of training data for regularization\n",
        "    colsample_bytree=0.8,   # Use a portion of features for each tree\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "# Fit the model on training data\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 7: Evaluate the model on training data\n",
        "y_train_pred = xgb_model.predict(X_train)\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "print(f\"Root Mean Squared Error (RMSE) on Training Data with XGBoost: {train_rmse}\")\n",
        "\n",
        "# Step 8: Use test data to make predictions\n",
        "# Predictions on the test dataset\n",
        "test_data['predicted_log_revenue'] = xgb_model.predict(X_test)\n",
        "\n",
        "# Convert predicted log revenue to revenue\n",
        "test_data['predicted_revenue'] = np.exp(test_data['predicted_log_revenue'])\n",
        "\n",
        "# Display results\n",
        "print(test_data[['id', 'predicted_revenue']])\n",
        "\n",
        "# Prepare submission DataFrame\n",
        "submission = test_data[['id', 'predicted_revenue']]\n",
        "\n",
        "# Rename columns to match the required format\n",
        "submission.columns = ['id', 'revenue']\n",
        "\n",
        "# Save to CSV\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"Submission file 'submission.csv' created successfully in the required format!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSUKZSruqf48",
        "outputId": "bc254825-87b5-481e-c3c2-8302e7862630"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE) on Training Data with XGBoost: 0.5695151501432907\n",
            "       id  predicted_revenue\n",
            "0    2175       3.789093e+04\n",
            "1    2564       1.085605e+07\n",
            "2    1493       1.342061e+07\n",
            "3     585       1.425776e+06\n",
            "4    2038       1.153648e+05\n",
            "..    ...                ...\n",
            "595  1588       3.259680e+07\n",
            "596   439       1.906126e+07\n",
            "597  2908       9.314447e+06\n",
            "598  1179       9.386971e+04\n",
            "599  1443       7.702862e+06\n",
            "\n",
            "[600 rows x 2 columns]\n",
            "Submission file 'submission.csv' created successfully in the required format!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load training and test datasets\n",
        "train_data = pd.read_csv(\"./train.csv\")\n",
        "test_data = pd.read_csv(\"./test.csv\")\n",
        "\n",
        "# Define helper function to extract date features\n",
        "def extract_date_features(dataframe):\n",
        "    dataframe['release_year'] = pd.to_datetime(dataframe['release_date'], errors='coerce').dt.year\n",
        "    dataframe['release_month'] = pd.to_datetime(dataframe['release_date'], errors='coerce').dt.month\n",
        "    dataframe['release_weekday'] = pd.to_datetime(dataframe['release_date'], errors='coerce').dt.weekday\n",
        "\n",
        "# Step 1: Create 'log_revenue' in training data\n",
        "train_data['log_revenue'] = np.log(train_data['revenue'].replace(0, np.nan))\n",
        "\n",
        "# Step 2: Feature engineering for dates in training data\n",
        "extract_date_features(train_data)\n",
        "\n",
        "# Step 3: Handle missing values\n",
        "# For XGBoost, we retain NaN values instead of filling them\n",
        "numeric_columns = train_data.select_dtypes(include=['float64', 'int64']).columns\n",
        "categorical_columns = train_data.select_dtypes(include=['object']).columns\n",
        "\n",
        "train_data[categorical_columns] = train_data[categorical_columns].fillna(\"Unknown\")\n",
        "\n",
        "# Step 4: One-hot encode categorical features in training data\n",
        "categorical_to_encode = ['main_genre', 'language']\n",
        "existing_categoricals = [col for col in categorical_to_encode if col in train_data.columns]\n",
        "train_data = pd.get_dummies(train_data, columns=existing_categoricals, drop_first=True)\n",
        "\n",
        "# Step 5: Define features and target for training\n",
        "target = \"log_revenue\"\n",
        "features = train_data.columns.difference([target, 'revenue', 'belongs_to_collection', 'genres', 'homepage',\n",
        "                                          'imdb_id', 'original_language', 'original_title', 'overview',\n",
        "                                          'poster_path', 'production_companies', 'production_countries',\n",
        "                                          'release_date', 'spoken_languages', 'status', 'tagline', 'title',\n",
        "                                          'Keywords', 'cast', 'crew'])\n",
        "\n",
        "X_train = train_data[features]\n",
        "y_train = train_data[target]\n",
        "\n",
        "# Step 6: XGBoost Grid Search for Hyperparameter Tuning\n",
        "xgb = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [4, 6, 8],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters from GridSearch\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Train the XGBoost model with best parameters\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "\n",
        "# Step 7: Evaluate the model on training data\n",
        "y_train_pred = best_xgb_model.predict(X_train)\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "print(f\"Root Mean Squared Error (RMSE) on Training Data: {train_rmse}\")\n",
        "\n",
        "# Step 8: Use test data to make predictions\n",
        "# Apply the same feature engineering steps to the test data\n",
        "extract_date_features(test_data)\n",
        "\n",
        "# Check for existence of categorical columns before handling them\n",
        "existing_categoricals = [col for col in categorical_to_encode if col in test_data.columns]\n",
        "if existing_categoricals:\n",
        "    test_data[existing_categoricals] = test_data[existing_categoricals].fillna(\"Unknown\")\n",
        "    test_data = pd.get_dummies(test_data, columns=existing_categoricals, drop_first=True)\n",
        "\n",
        "# Align test data columns to match training data's features\n",
        "X_test = test_data.reindex(columns=features, fill_value=0)\n",
        "\n",
        "# Predict on the test dataset\n",
        "test_data['predicted_log_revenue'] = best_xgb_model.predict(X_test)\n",
        "\n",
        "# Convert predicted log revenue to revenue\n",
        "test_data['predicted_revenue'] = np.exp(test_data['predicted_log_revenue'])\n",
        "\n",
        "# Display results\n",
        "print(test_data[['id', 'predicted_revenue']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o32RBH0ut2Wq",
        "outputId": "3f8ba3a1-a993-420d-8920-6ef1a153cd01"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-bbfb65306126>:13: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  dataframe['release_year'] = pd.to_datetime(dataframe['release_date'], errors='coerce').dt.year\n",
            "<ipython-input-7-bbfb65306126>:14: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  dataframe['release_month'] = pd.to_datetime(dataframe['release_date'], errors='coerce').dt.month\n",
            "<ipython-input-7-bbfb65306126>:15: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  dataframe['release_weekday'] = pd.to_datetime(dataframe['release_date'], errors='coerce').dt.weekday\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.5s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.8; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.8; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.8; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=1.0; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=1.0; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=1.0; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=200, subsample=1.0; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=200, subsample=1.0; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=200, subsample=1.0; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=0.8; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=0.8; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=0.8; total time=   3.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=1.0; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=1.0; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=1.0; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=0.8; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=0.8; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=1.0; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, n_estimators=100, subsample=0.8; total time=   1.6s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, n_estimators=100, subsample=1.0; total time=   1.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, n_estimators=200, subsample=1.0; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, n_estimators=200, subsample=1.0; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, n_estimators=200, subsample=1.0; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, n_estimators=300, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, n_estimators=300, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, n_estimators=300, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, n_estimators=300, subsample=1.0; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, n_estimators=300, subsample=1.0; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=8, n_estimators=300, subsample=1.0; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.0s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   2.0s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.8; total time=   2.4s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.8; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.8; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1.0; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=   1.4s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=200, subsample=0.8; total time=   1.4s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=200, subsample=1.0; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=200, subsample=1.0; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=200, subsample=1.0; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=1.0; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=1.0; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=1.0; total time=   0.7s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.4s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.5s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.4s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.4s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=1.0; total time=   0.5s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=1.0; total time=   0.5s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=1.0; total time=   0.5s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.4s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.4s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.4s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=200, subsample=1.0; total time=   0.8s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=200, subsample=1.0; total time=   2.6s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=200, subsample=1.0; total time=   1.7s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=0.8; total time=   1.0s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=0.8; total time=   1.0s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=0.8; total time=   1.0s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=1.0; total time=   1.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=1.0; total time=   1.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=1.0; total time=   1.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.3s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.5s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.8s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=0.8; total time=   0.4s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=1.0; total time=   0.4s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=1.0; total time=   0.8s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=300, subsample=1.0; total time=   0.4s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.4s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.4s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.4s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.4s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=200, subsample=1.0; total time=   0.9s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=200, subsample=1.0; total time=   2.3s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=200, subsample=1.0; total time=   1.3s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=300, subsample=0.8; total time=   0.9s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=300, subsample=0.8; total time=   0.9s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=300, subsample=0.8; total time=   0.9s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=300, subsample=1.0; total time=   0.9s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=300, subsample=1.0; total time=   0.8s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=300, subsample=1.0; total time=   0.9s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.1s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   0.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.6s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   1.0s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   1.0s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.8; total time=   0.4s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.8; total time=   0.4s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1.0; total time=   0.4s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1.0; total time=   0.4s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1.0; total time=   0.4s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.3s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.4s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=200, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=200, subsample=1.0; total time=   0.6s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=200, subsample=1.0; total time=   0.6s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=200, subsample=1.0; total time=   0.6s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=0.8; total time=   0.9s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=0.8; total time=   3.2s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=0.8; total time=   0.9s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=1.0; total time=   0.9s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=1.0; total time=   0.8s\n",
            "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=1.0; total time=   0.9s\n",
            "Best Hyperparameters: {'colsample_bytree': 1.0, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100, 'subsample': 0.8}\n",
            "Root Mean Squared Error (RMSE) on Training Data: 1.9290674400113856\n",
            "       id  predicted_revenue\n",
            "0    2175       1.542528e+05\n",
            "1    2564       8.359168e+06\n",
            "2    1493       1.508013e+07\n",
            "3     585       7.613820e+05\n",
            "4    2038       3.487447e+05\n",
            "..    ...                ...\n",
            "595  1588       4.368270e+07\n",
            "596   439       1.856158e+07\n",
            "597  2908       1.128289e+07\n",
            "598  1179       1.362523e+05\n",
            "599  1443       1.334144e+07\n",
            "\n",
            "[600 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-bbfb65306126>:13: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  dataframe['release_year'] = pd.to_datetime(dataframe['release_date'], errors='coerce').dt.year\n",
            "<ipython-input-7-bbfb65306126>:14: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  dataframe['release_month'] = pd.to_datetime(dataframe['release_date'], errors='coerce').dt.month\n",
            "<ipython-input-7-bbfb65306126>:15: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  dataframe['release_weekday'] = pd.to_datetime(dataframe['release_date'], errors='coerce').dt.weekday\n"
          ]
        }
      ]
    }
  ]
}